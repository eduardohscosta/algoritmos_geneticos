\chapter{Computação Evolucionária}

O contexto da criação e desenvolvimento dos algorítimos genéticos (AG) está intrinsecamente ligado à área de estudos da computação evolucionária que, por sua vez, está sob o guarda-chuva da área de pesquisa da inteligência artificial. Com isso, neste capítulo, procura-se realizar uma contextualização histórica à computação evolucionária, à programação evolucionária, às estratégias evolutivas e aos algoritmos genéticos, objetivando, assim, um maior entendimento de como o desenvolvimento das pesquisas nestas áreas contribuíram para o campo dos algoritmos genéticos.

\section{Introdução}

Como o próprio nome sugere, a computação evolucionária (CE) tem como inspiração os processos de evolução observados nos organismos da natureza, sendo uma metáfora computacional (vide \autoref{tab:EvolutionaryComputingMetaphor}) que, de forma geral, visa solucionar problemas computacionais ou entender melhor os processos naturais de evolução. Através de uma simulação destes processos naturais, busca-se pelos indivíduos mais aptos a sobreviverem em um ambiente, assim como analisar como os processos de reprodução e mutação destes indivíduos ocorreram. O próprio ambiente é, em si, um dos elementos mais importantes neste conjunto, tendo grande influência nessa luta pela sobrevivência e a busca de parceiros para reprodução e determinando como a capacidade de se adaptar a esse meio influenciará em suas chances de passar seus genes para as próximas gerações.

\begin{table}[h!]
	\caption{\uppercase{Metáfora da Computação Evolucionária}}
	\small
	\centering
	\vspace{2pt}
	\def\arraystretch{1.2}
	\begin{tabular}{ |ccc| }
		\hline
		Evolution & ~ & Problem solving \\ \hline
		Environment & $\Longleftrightarrow$ & Problem \\
		Individual & $\Longleftrightarrow$ & Candidate solution \\
		Fitness & $\Longleftrightarrow$ & Quality \\ \hline
	\end{tabular}
	\label{tab:EvolutionaryComputingMetaphor}
	\begin{minipage}{1 \textwidth}
		\centering
		\vspace{6pt}
		FONTE:~\cite{eiben_introduction_2015}
	\end{minipage}
\end{table}

Ao fim de 1950, e meados da década de 60, a tecnologia havia avançado até chegar à computação digital, o que possibilitou um avanço na experimentação de novos modelos de processos evolucionários e um grande número de estudos nas décadas seguintes. Os trabalhos de \cite{learning_machine_1958}, \cite{Friedberg1959ALM} e \cite{bremermann_optimization_1962} são apontados como os primeiros registros de desenvolvimento de processos evolucionários aplicados no contexto de problemas computacionais. Os trabalhos de Friedberg podem ser considerados alguns dos primeiros estudos em \textit{machine learning}\footnote{Do inglês, aprendizado de máquina.} e programação automática \Citep{back_handbook_1997}.

\cite{bremermann_optimization_1962}, publica sua pesquisa de evolução simulada aplicada à otimização linear e convexa e equações simultâneas não lineares, assim como desenvolve, em 1965\footnote{\cite{search_evolution_biophysics_1965}}, um dos primeiros estudos teóricos sobre algoritmos evolucionários, demonstrando que a mutação ótima deve ter um valor $\frac{1}{l}$\footnote{\textit{length}, do inglês, comprimento} no caso de $l$ bits codificados como indivíduos quando aplicados a problemas linearmente separáveis \Citep{back_handbook_1997}.

Com as contribuições dos trabalhados acima apresentados, as pesquisas realizadas na segunda metade dos anos 1960 estabeleceram os três principais campos de estudo em CE, sendo eles a programação evolucionária (PE), as estratégias evolutivas (EE) e os algoritmos genéticos (AG). Na segunda metade da década de 1960, Lawrance Fogel\footnote{\cite{Fogel1966ArtificialIT}} construía as bases da programação evolucionária em San Diego, Califórnia, e John Holland fundava as bases dos algoritmos genéticos na Universidade de Michigan\footnote{\cite{holland_1962}}. Por sua vez, as estratégias evolutivas eram desenvolvidas por Inge Rechenberg, Peter Bienert e Hans-Paul Schwefel em Berlim em meados de 1965\footnote{\cite{rechenberg_cybernetic_1965}}.

Como aponta \cite{back_handbook_1997}, mesmo com cada uma das áreas seguindo seu próprio caminho de pesquisas ao longo dos quase 30 anos seguintes, a década de 1990 marca o encontro destes campos através dos esforços de seus pesquisadores na organização de diversos congressos com o objetivo de compartilharem os conhecimentos até então absorvidos, culminando, no início dos anos 1990, no consenso do nome \textbf{computação evolucionária} (destacado pelo autor) como o nome dessa nova grande área de pesquisa. A partir destas reuniões, o crescimento do número de interessados e novos trabalhos foi naturalmente crescendo ao longo da década. Em 1993, é criado um periódico homônimo pelo Instituto de Tecnologia de Massachusetts\footnote{Evolutionary Computation \citeyearpar{noauthor_editorial_1993}} e, em 1994, uma das três conferências do Congresso Mundial de Inteligência Computacional organizado pelo Instituto de Engenheiros Eletricistas e Eletrônicos\footnote{\textit{IEEE World Congress on Computaional Intelligence} (WCCI)} \citeapud{back_handbook_1997}{michalewicz_1994}.

\section{Programação Evolucionária}

Desenvolvida por Lawrance Fogel na década de 1960, a programação evolucionária (PE) foi construída sobre diversos experimentos visando a previsão, sob algum critério arbitrário, de séries temporais não estacionárias através da evolução simulada dos estados das máquinas dentro de um limite de estados predeterminados, ou seja, dado os estados passados, previa-se os estados da máquina resultantes deste processo. Fogel buscou seguir um caminho diferente de pesquisa em relação ao que os trabalhos em inteligência artificial se concentravam à época, uma simulação primitiva de redes neurais. Para Fogel, havia uma grande limitação dos modelos baseados na inteligência humana em relação aos processos de criaturas com desenvolvimento contínuo do intelecto, necessário para sobrevivência em um dado ambiente (evolução).

Segundo \citet[pg.A2.3:3]{back_handbook_1997}, Fogel apresenta as primeiras tentativas de \enquote{[...](i) usar a evolução simulada para realizar predições, (ii) incluir codificações de comprimento variável, (iii) usar representações que tomam a forma de uma sequência de instrução, (iv) incorporar uma população de soluções candidatas e (v) coevoluir programas evolutivos} e partindo da premissa que \enquote{a inteligência é baseada na adaptação do comportamento para atingir metas em uma variedade de ambientes} (tradução nossa)\footnote{\textit{[...] (i) use simulated evolution to perform prediction, (ii) include variable-length encodings, (iii) use representations that take the form of a sequence of instructions, (iv) incorporate a population of candidate solutions, and (v) coevolve evolutionary programs [...] considered intelligence to be based on adapting behavior to meet goals in a range of environments.}}.

Devido ao contexto computacional, esses ambientes eram representados através de uma sequência de símbolos ou caracteres de um alfabeto finito arbitrário e o problema evolutivo definido como uma sequência de instruções, ou algoritmo, aplicadas sobre o conjunto de símbolos já observados. Com isso, ao inserir um conjunto de máquinas (população) em um dado ambiente, onde cada máquina possui um valor definido como o valor de entrada, esperava-se melhorar a performance de previsão do algoritmo, à medida que o valor de saída, ou o resultado, era comparado com o próximo valor de entrada. A qualidade desta previsão era, então, medida por uma função de recompensa que indicava o quanto cada máquina da população se adaptou ao ambiente.

Cada máquina pai pode criar um ou mais descendentes, onde cada descendente é criado pelo processo aleatório de alteração de estado, ou valor, do pai. Esse processo de mutação pode ocorrer sob uma certa distribuição de probabilidade ou ser definido no início da implementação do algoritmo. Ao fim de cada geração, a função de recompensa é aplicada sobre o descendente, assim como foi feito com seu pai, para avaliar o quão apto está em relação ao ambiente. As máquinas que fornecem o maior valor de recompensa permanecem no ambiente e se tornam pais das máquinas da geração seguinte. Este processo acontece sucessivas vezes até o símbolo que o símbolo que se deseja prever seja, efetivamente, previsto. A melhor máquina irá gerar essa previsão e esse novo símbolo é adicionado na população para ser avaliado no ambiente, reiniciando, assim, o processo.

Esse algoritmo foi aplicado com êxito em problemas de previsão, identificação e controle automático, simulação de coevolução de populações, experimentos de previsão de sequência, reconhecimento de padrões e em jogos. Na década de 1980, o algoritmo estendeu-se para novas aplicações, como no ordenamento de itens no problema do caixeiro viajante e em funções de otimização contínua, evoluindo, posteriormente, para implementações em planejamento de rotas, seleção ótima de subconjuntos e treinamento de redes neurais. No início da década de 1990, ocorre a primeira conferência anual de programação evolucionária, com exemplos de diversas aplicações de otimização na área de robótica, planejamento de caminhos e rotas, desenho e treinamento de redes neurais, controle automática entre outros \citeapud{back_handbook_1997}{michalewicz_1994}.

\section{Estratégias Evolutivas} 

No meio da década de 1960, Bienert, Rechenberg e Schwefel, três estudantes da Universidade Técnica de Berlim, estudavam modelos de otimização aplicados em problemas da área de aerotecnologia e tecnologia espacial. Uma das principais pesquisas que realizavam à época, era de um robô experimental que, em um túnel de vento, deveria realizar uma série de testes em uma estrutura tridimensional fina e flexível visando minimizar a resistência em relação ao ar. Os primeiros testes não obtiveram sucesso. Foi apenas no ano seguinte ao início dos testes que \cite{rechenberg_cybernetic_1965} decide utilizar um dado para decisões aleatórias elaborando, assim, a primeira versão de uma EE \cite[pg.A2.3:6]{back_handbook_1997} chamada, posteriormente, de $(1 + l) EE$. 

Essa primeira versão consiste em uma sequência de instruções projetadas para otimização contínua bastante similar à busca aleatória, exceto por uma regra para a força da mutação conhecida como \enquote{regra do sucesso $\frac{1}{5}$} para ajuste do desvio padrão dessa mutação. Como a notação sugere, a estratégia de evolução $(1 + l)$ possui apenas um indivíduo pai que irá gerar apenas um indivíduo filho, onde ambos são confrontados e o indivíduo que representa a solução mais fraca, morre. Este indivíduo sobrevivente gera um novo filho e, assim, repetindo essa sequência diversas até se chegar a uma solução ótima. Sendo executado indivíduo a indivíduo, esse processo é computacionalmente custoso, apresentando uma convergência lenta para uma solução ótima, assim como tem a possibilidade de convergir para uma solução local.

Devido aos problemas de desempenho, os autores trabalharam em melhorias na estrutura do algoritmo, desenvolvendo uma nova versão chamada de EE multi-membro\footnote{\textit{EE multimembered}.} com população maior que 1. Novas melhorias foram realizadas nessa nova versão, resultando em dois princípios principais: $(\mu+1)$ e $(\mu, 1)$. No primeiro, $\mu$ indivíduos produzem $\lambda$ descendentes, gerando uma população temporária de $(\mu + \lambda)$ novos indivíduos, havendo a seleção de $\mu$ indivíduos para a geração seguinte. No segundo tipo, $\mu$ indivíduos produzem $\lambda$ descendentes, com $\mu < \lambda$, onde a nova população de $\mu$ indivíduos possui apenas os indivíduos selecionados do conjunto de $\lambda$ descendentes, limitando o tempo de vida de um indivíduo apenas a uma geração específica.

A partir da primeira versão, a comunidade de pesquisadores da área de EE realizaram novas aplicações nas décadas seguintes que não se reduziram somente ao objetivo da otimização de valores do mundo real, como a aplicação para otimização binária em estruturas de indivíduos multicelulares usando a ideia de sub populações, estratégias evolutivas para problemas com multi critérios, entre diversas outras aplicações seguindo a ideia principal de melhoria contínua dos indivíduos analisados \Citep{back_handbook_1997}.

\section{Algoritmos Genéticos} 

Conforme aponta \Citet[pg.A2.3:4]{back_handbook_1997}, as primeiras ideias que deram origem aos algoritmos genéticos datam do início da década de 1960 nos trabalhos de \cite{holland_1962}, que \enquote{estabeleceu uma agenda ampla e ambiciosa para compreender os princípios subjacentes dos sistemas adaptativos – sistemas que são capazes de automodificação em resposta às suas interações com os ambientes em que devem funcionar} (tradução nossa)\footnote{\textit{Holland set out a broad and ambitious agenda for understanding the underlying principles of adaptive systems—systems that are capable of self-modification in response to their interactions with the environments in which they must function.}}.

Diferentemente dos estudos apresentados anteriormente de algoritmos aplicados em modelos de previsão ou otimização, Holland se debruçou sobre modelos evolutivos para entendimento de sistemas adaptativos robustos naturais e projeção de elementos adaptativos em um dado contexto. Para o autor, em sistemas adaptativos naturais, as características relativas à competição entre os agentes e de inovação ao longo destes processos naturais eram fundamentais para que os indivíduos se adaptassem ao ambiente e às mudanças imprevistas que este ambiente aplicava sobre esses indivíduos \Citep{back_handbook_1997}.

Para \cite[p. 1]{goldberg_genetic_1989}, eram dois os principais objetivos de John Holland e seus colegas no campo de pesquisa dos AGs, sendo eles: uma explicação bem estruturada e fundamentada dos processos de adaptação de sistemas naturais e a construção de programas computacionais de sistemas artificiais com a finalidade de incorporar importantes mecanismos destes sistemas, sendo o foco da pesquisa a robustez dos algoritmos, ou seja, o equilíbrio entre a eficiência e a eficácia necessária para a sobrevivência de possíveis soluções em muitos ambientes diferentes.

O grande deferencial da linha desenvolvida por Holland, foi a incorporação de diversos conceitos da genética que se demonstraram de alta eficiência e performance na resolução de problemas complexos utilizando poucos dados de entrada, assim como os processos de busca para encontrar soluções ótimas apresentavam inovações em relação à resolução de tais problemas e aprendizados dos elementos no ambiente ao longo dos processos evolutivos. Os elementos a serem evoluídos ao longo de um período eram representados como genomas (conjunto de todos os genes de um ser vivo) e os mecanismos de evolução como abstrações de operadores genéticos como a reprodução, cruzamento e mutação.

Em 1967, Holland realiza estudos em uma teoria geral de sistemas adaptativos, desenvolvendo no mesmo período a análise de esquemas de sistemas adaptativos e, em 1969, demonstra aplicações de alocação ótima utilizando o modelo de k-bandidos armados \citeapud{holland_1967}{back_handbook_1997}. \cite{cavicchio_adaptive_1970} absorveu essas ideias como uma forma de busca adaptativa e as testou em problemas de busca complexa envolvendo soluções de subrotinas e reconhecimento de padrões, assim como alguns dos primeiros estudos sobre formas elitistas de seleção e adaptação de taxas de cruzamento e mutação. \cite{university_of_michigan_artificial_1971}, por sua vez, apresentou ideias aprofundadas de seleção alternada e, através de experimentações em paisagens de adaptação bidimensionais, testou diversos modelos de estratégias de reprodução com origem em técnicas utilizadas por criadores de animais. Em 1975, Holland agrupa as ideias desenvolvidas em seus trabalhos e publica o seu maior trabalho, o livro Adaptação em Sistemas Naturais e Artificiais \Citep{holland_adaptation_1975}. No mesmo ano, \cite{jong_analysis_1975} publica experimentos demonstrando teórica e praticamente os efeitos no tamanho da população, cruzamento e mutação de AGs aplicados em uma população, seguindo as ideias de Holland.

O interesse pela área foi crescendo progressivamente nas décadas seguintes. Em 1976, pesquisadores da Universidade de Michigan, Universidade de Pittsburgh, entre outras, organizaram a primeira conferência de sistemas adaptativos, que ocorreu nos anos seguintes. Em 1979, Holland, De Jong e Sampson escalam o tamanho da conferência através de um financiamento para realizarem uma conferência interdisciplinar em sistemas adaptativos, que acabou sendo realizado em 1981 na Universidade de Michigan. Em 1985, na Universidade de Pittsburgh, ocorre a Conferência Internacional sobre Algoritmos Genéticos (ICGA) que, devido ao sucesso, passou a ser semestral nos anos seguintes. Em 1989, surge a Sociedade Internacional de Algoritmos Genéticos (ISGA), organização responsável pelo financiamento de conferências e atividades das áreas de pesquisas relacionadas aos AGs, tendo como uma de suas primeiras conquistas a criação de uma das principais conferências da comunidade, sobre os Fundamentos dos Algoritmos Genéticos (FOGA) \cite[pg.A2.3:5]{back_handbook_1997}.
