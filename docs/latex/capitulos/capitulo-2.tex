\chapter{Computação Evolucionária}

O contexto da criação e desenvolvimento dos algoritmos genéticos está intrinsecamente ligado à área de estudos da computação evolucionária que, por sua vez, está sob o guarda-chuva da área de pesquisa da inteligência artificial. Com o objetivo de entender o desenvolvimento dos algoritmos genéticos, desde sua criação, procura-se, neste capítulo, realizar uma contextualização histórica à computação evolucionária, à programação evolucionária, às estratégias evolutivas, além da evolução e principais contribuições para o desenvolvimento dos algoritmos genéticos até sua formalização como campo de pesquisa.

\section{Introdução}

Como o próprio nome sugere, a computação evolucionária (CE) tem como inspiração os processos de evolução observados nos organismos da natureza, sendo uma metáfora computacional (vide \autoref{tab:EvolutionaryComputingMetaphor}) que, de forma geral, visa solucionar problemas computacionais ou entender melhor os processos naturais de evolução. Através de uma simulação destes processos naturais, busca-se pelos indivíduos mais aptos a sobreviverem em um ambiente, assim como analisar como os processos de reprodução e mutação destes indivíduos ocorreram. O próprio ambiente é, em si, um dos elementos mais importantes neste conjunto, tendo grande influência nessa luta pela sobrevivência e na busca de parceiros para reprodução, determinando, assim, como a capacidade de se adaptar a esse meio influenciará em suas chances de passar seus genes para as próximas gerações.

\tabelasimples
	{ccc}
	{Metáfora da Computação Evolucionária}
	{%
		Evolution & ~ & Problem solving \\ \hline
		Environment & $\Longleftrightarrow$ & Problem \\
		Individual & $\Longleftrightarrow$ & Candidate solution \\
		Fitness & $\Longleftrightarrow$ & Quality \\ \hline
	}
	{EvolutionaryComputingMetaphor}
	{\citet[p.11]{eiben_introduction_2015}}

Ao fim de 1950, e meados da década de 60, a tecnologia havia avançado até chegar à computação digital, o que possibilitou um avanço na experimentação de novos modelos de processos evolucionários e um grande número de estudos nas décadas seguintes. Os trabalhos de \cite{learning_machine_1958}, \cite{Friedberg1959ALM} e \cite{bremermann_optimization_1962} são apontados como os primeiros registros de desenvolvimento de processos evolucionários aplicados no contexto de problemas computacionais. Os trabalhos de Friedberg podem ser considerados alguns dos primeiros estudos em \textit{machine learning}\footnote{Do inglês, aprendizado de máquina.} e programação automática \Citep{back_handbook_1997}.

\cite{bremermann_optimization_1962}, publica sua pesquisa de evolução simulada aplicada à otimização linear e convexa e equações simultâneas não lineares, assim como desenvolve, em 1965\footnote{\cite{search_evolution_biophysics_1965}}, um dos primeiros estudos teóricos sobre algoritmos evolucionários, demonstrando que a mutação ótima deve ter um valor $\frac{1}{l}$\footnote{\textit{length}, do inglês, comprimento} no caso de $l$ bits codificados como indivíduos quando aplicados a problemas linearmente separáveis \Citep{back_handbook_1997}.

Com as contribuições dos trabalhados acima apresentados, as pesquisas realizadas na segunda metade dos anos 1960 estabeleceram os três principais campos de estudo em CE, sendo eles a programação evolucionária (PE), as estratégias evolutivas (EE) e os algoritmos genéticos (AG). Na segunda metade da década de 1960, Lawrance Fogel\footnote{\cite{Fogel1966ArtificialIT}} construía as bases da programação evolucionária em San Diego, Califórnia, e John Holland fundava as bases dos algoritmos genéticos na Universidade de Michigan\footnote{\cite{holland_1962}}. Por sua vez, as estratégias evolutivas eram desenvolvidas por Inge Rechenberg, Peter Bienert e Hans-Paul Schwefel em Berlim em meados de 1965\footnote{\cite{rechenberg_cybernetic_1965}}.

Como aponta \cite{back_handbook_1997}, mesmo com cada uma das áreas seguindo seu próprio caminho de pesquisas ao longo dos quase 30 anos seguintes, a década de 1990 marca o encontro destes campos através dos esforços de seus pesquisadores na organização de diversos congressos com o objetivo de compartilharem os conhecimentos até então absorvidos, culminando, no início da década, no consenso do nome \textbf{computação evolucionária} como o nome dessa nova grande área de pesquisa. A partir destas reuniões, o crescimento do número de interessados e novos trabalhos foi naturalmente crescendo ao longo da década. Em 1993, é criado um periódico homônimo pelo Instituto de Tecnologia de Massachusetts\footnote{Evolutionary Computation \citeyearpar{noauthor_editorial_1993}} e, em 1994, uma das três conferências do Congresso Mundial de Inteligência Computacional organizado pelo Instituto de Engenheiros Eletricistas e Eletrônicos\footnote{\textit{IEEE World Congress on Computaional Intelligence} (WCCI)} \citeapud{back_handbook_1997}{michalewicz_1994}.

\section{Programação Evolucionária}

Desenvolvida por Lawrance Fogel na década de 1960, a programação evolucionária (PE) foi construída sobre diversos experimentos visando a previsão, sob algum critério arbitrário, de séries temporais não estacionárias através da evolução simulada dos estados das máquinas dentro de um limite de estados predeterminados, ou seja, dado os estados passados, previa-se os estados da máquina resultantes deste processo. Fogel buscou seguir um caminho diferente de pesquisa em relação ao que os trabalhos em inteligência artificial se concentravam à época, uma simulação primitiva de redes neurais. Para Fogel, havia uma grande limitação dos modelos baseados na inteligência humana em relação aos processos de criaturas com desenvolvimento contínuo do intelecto, necessário para sobrevivência em um dado ambiente (evolução).

Segundo \citet[pg.A2.3:3]{back_handbook_1997}, Fogel apresenta as primeiras tentativas de \enquote{[...](i) usar a evolução simulada para realizar predições, (ii) incluir codificações de comprimento variável, (iii) usar representações que tomam a forma de uma sequência de instrução, (iv) incorporar uma população de soluções candidatas e (v) coevoluir programas evolutivos} e partindo da premissa que \enquote{a inteligência é baseada na adaptação do comportamento para atingir metas em uma variedade de ambientes} (tradução nossa)\footnote{\textit{[...] (i) use simulated evolution to perform prediction, (ii) include variable-length encodings, (iii) use representations that take the form of a sequence of instructions, (iv) incorporate a population of candidate solutions, and (v) coevolve evolutionary programs [...] considered intelligence to be based on adapting behavior to meet goals in a range of environments.}}.

Devido ao contexto computacional, esses ambientes eram representados através de uma sequência de símbolos ou caracteres de um alfabeto finito arbitrário e o problema evolutivo definido como uma sequência de instruções, ou algoritmo, aplicadas sobre o conjunto de símbolos já observados. Com isso, ao inserir um conjunto de máquinas (população) em um dado ambiente, onde cada máquina possui um valor definido como o valor de entrada, esperava-se melhorar a performance de previsão do algoritmo, à medida que o valor de saída, ou o resultado, era comparado com o próximo valor de entrada. A qualidade desta previsão era, então, medida por uma função de recompensa que indicava o quanto cada máquina da população se adaptou ao ambiente.

Cada máquina pai pode criar um ou mais descendentes, onde cada descendente é criado pelo processo aleatório de alteração de estado, ou valor, do pai. Esse processo de mutação pode ocorrer sob uma certa distribuição de probabilidade ou ser definido no início da implementação do algoritmo. Ao fim de cada geração, a função de recompensa é aplicada sobre o descendente, assim como foi feito com seu pai, para avaliar o quão apto está em relação ao ambiente. As máquinas que fornecem o maior valor de recompensa permanecem no ambiente e se tornam pais das máquinas da geração seguinte. Este processo acontece sucessivas vezes até o símbolo que o símbolo que se deseja prever seja, efetivamente, previsto. A melhor máquina irá gerar essa previsão e esse novo símbolo é adicionado na população para ser avaliado no ambiente, reiniciando, assim, o processo.

Esse algoritmo foi aplicado com êxito em problemas de previsão, identificação e controle automático, simulação de coevolução de populações, experimentos de previsão de sequência, reconhecimento de padrões e em jogos. Na década de 1980, o algoritmo estendeu-se para novas aplicações, como no ordenamento de itens no problema do caixeiro viajante e em funções de otimização contínua, evoluindo, posteriormente, para implementações em planejamento de rotas, seleção ótima de subconjuntos e treinamento de redes neurais. No início da década de 1990, ocorre a primeira conferência anual de programação evolucionária, com exemplos de diversas aplicações de otimização na área de robótica, planejamento de caminhos e rotas, desenho e treinamento de redes neurais, controle automática entre outros \citeapud{back_handbook_1997}{michalewicz_1994}.

\section{Estratégias Evolutivas} 

Na metade da década de 1960, Bienert, Rechenberg e Schwefel, três estudantes da Universidade Técnica de Berlim, estudavam modelos de otimização aplicados em problemas da área de aerotecnologia e tecnologia espacial. Uma das principais pesquisas que realizavam à época, era de um robô experimental que, em um túnel de vento, deveria realizar uma série de testes em uma estrutura tridimensional fina e flexível visando minimizar a resistência em relação ao ar. Os primeiros testes não obtiveram sucesso. Foi apenas no ano seguinte ao início dos testes que \cite{rechenberg_cybernetic_1965} decide utilizar um dado para decisões aleatórias elaborando, assim, a primeira versão de uma EE \cite[pg.A2.3:6]{back_handbook_1997} chamada, posteriormente, de $(1 + l) EE$. 

Essa primeira versão consiste em uma sequência de instruções projetadas para otimização contínua bastante similar à busca aleatória, exceto por uma regra para a força da mutação conhecida como \enquote{regra do sucesso $\frac{1}{5}$} para ajuste do desvio padrão dessa mutação. Como a notação sugere, a estratégia de evolução $(1 + l)$ possui apenas um indivíduo pai que irá gerar apenas um indivíduo filho, onde ambos são confrontados e o indivíduo que representa a solução mais fraca, morre. Este indivíduo sobrevivente gera um novo filho e, assim, repetindo essa sequência diversas até se chegar a uma solução ótima. Sendo executado indivíduo a indivíduo, esse processo é computacionalmente custoso, apresentando uma convergência lenta para uma solução ótima, assim como tem a possibilidade de convergir para uma solução local.

Devido aos problemas de desempenho, os autores trabalharam em melhorias na estrutura do algoritmo, desenvolvendo uma nova versão chamada de EE multi-membro\footnote{\textit{EE multimembered}.} com população maior que 1. Novas melhorias foram realizadas nessa nova versão, resultando em dois princípios principais: $(\mu+1)$ e $(\mu, 1)$. No primeiro, $\mu$ indivíduos produzem $\lambda$ descendentes, gerando uma população temporária de $(\mu + \lambda)$ novos indivíduos, havendo a seleção de $\mu$ indivíduos para a geração seguinte. No segundo tipo, $\mu$ indivíduos produzem $\lambda$ descendentes, com $\mu < \lambda$, onde a nova população de $\mu$ indivíduos possui apenas os indivíduos selecionados do conjunto de $\lambda$ descendentes, limitando o tempo de vida de um indivíduo apenas a uma geração específica.

A partir da primeira versão, a comunidade de pesquisadores da área de EE realizaram novas aplicações nas décadas seguintes que não se reduziram somente ao objetivo da otimização de valores do mundo real, como a aplicação para otimização binária em estruturas de indivíduos multicelulares usando a ideia de sub populações, estratégias evolutivas para problemas com multi critérios, entre diversas outras aplicações seguindo a ideia principal de melhoria contínua dos indivíduos analisados \Citep{back_handbook_1997}.

\section{Algoritmos Genéticos} 
\label{sec:AlgoritmosGeneticos}

No início da década de 1960, na Universidade de Michigan, John H. Holland\footnote{John Henry Holland foi um bacharel em Matemática pelo Instituto de Tecnologia de Massachusetts, com mestrado na mesma área. Em 1959, é a primeira pessoa a receber o título de Ph.D (Doutor) da Universidade de Michigan em Ciência da Computação. Holland foi um dos responsáveis pela criação do primeiro Centro de Estudos de Sistemas Complexos, em Michigan. Na segunda metade da década de 1980, se torna uns dos principais membros do Instituto Santa Fe, no Novo México, que pesquisava fenômenos não-lineares. Da conquista de seu título de Doutor até seu falecimento, em 9 de agosto de 2015, permaneceu como professor na Universidade de Michigan lecionando nas disciplinas de Economia, Biologia e Ciência da Computação \citep{britannica_2022}.} e seus alunos davam os primeiros passos nos estudos de operadores genéticos para resolução de problemas em ambientes artificiais. Previamente aos primeiros estudos de Holland, é válido citar que o uso de computadores para simular sistemas artificiais ou genéticos com o objetivo de observar fenômenos naturais já era tema de pesquisa em trabalhos de biólogos que buscavam entender como a interação entre os indivíduos de uma população impactavam nas gerações subsequentes \citep[p.90]{goldberg_genetic_1989}.

Em 1962, em seu artigo intitulado \enquote{\textit{Outline for a Logical Theory of Adaptive Systems}}, Holland apresenta as primeiras ideias de sua Teoria de Sistemas Adaptativos que, conforme o autor apresenta, tinha o seguinte objetivo \citep{holland_1962}:

\citacao
	{%
		[...] delinear uma teoria de autômatos adequada às propriedades, requisitos e questões de adaptação. As condições que tal teoria deve satisfazer vêm não de um, mas de vários campos: deve ser possível formular, pelo menos em uma versão abstrata, algumas das principais hipóteses e problemas de partes relevantes da biologia, particularmente as áreas relacionadas ao controle molecular e neurofisiologia. [...] Em linhas gerais, é um estudo de como os sistemas podem gerar procedimentos que lhes permitam se ajustar de forma eficiente aos seus ambientes. Para que a adaptabilidade não seja arbitrariamente restringida no início, o sistema de adaptação deve ser capaz de gerar qualquer método ou procedimento capaz de uma definição efetiva. [...] O processo de adaptação pode, então, ser visto como uma modificação do processo de geração à medida que as informações sobre o ambiente se acumulam. Isso sugere que os sistemas adaptativos sejam estudados em termos de classes associadas de procedimentos de geração – a classe associada em cada caso sendo o repertório do sistema adaptativo. [...] A adaptação, então, baseia-se na seleção diferencial de programas de supervisão. Ou seja, quanto mais "bem-sucedido" for um programa de supervisão, em termos da capacidade de seus programas de resolução de problemas produzirem soluções, mais predominante ele se tornará (em números) em uma população de programas de supervisão.
	}{%
		[...] to outline a theory of automata appropriate to the properties, requirements and questions of adaptation. The conditions that such a theory should satisfy come from not one but several fields: It should be possible to formulate, at least in an abstract version, some of the key hypotheses and problems from relevant parts of biology, particularly the areas concerned with molecular control and neurophysiology. [...] In general terms, it is a study of how systems can generate procedures enabling them to adjust efficiently to their environments. If adaptability is not to be arbitrarily restricted at the outset, the adapting system must be able to generate any method or procedure capable of an effective definition. [...] The process of adaptation can then be viewed as a modification of the generation process as information about the environment accumulates. This suggests that adaptive systems be studied in terms of associated classes of generation procedures--the associated class in each case being the repertory of the adaptive system. [...] Adaptation, then, is based upon differential selection of supervisory programs. That is, the more "successful" a supervisory program, in terms of the ability of its problem-solving programs to produce solutions, the more predominant it is to become (in numbers) in a population of supervisory programs.
	}
	{\citep[p.297-298]{holland_1962}}
	{(tradução nossa).}

Dessa forma, Holland buscou nas décadas seguintes desenvolver uma teoria com os procedimentos necessários para criação de máquinas e programas computacionais que pudessem resolver problemas gerais com alta capacidade de adaptação a ambientes complexos através de alguns operadores que selecionariam, dentre um conjunto de programas ou máquinas, o mais apto à sobrevivência. Em outras palavras, os mais bem-sucedidos em encontrar uma solução para um dado problema, tinha maior chance de ser escolhido e novamente testado.

Segundo \Citet[pg.A2.3:4]{back_handbook_1997}, Holland \enquote{[...] estabeleceu uma agenda ampla e ambiciosa para compreender os princípios subjacentes dos sistemas adaptativos – sistemas que são capazes de automodificação em resposta às suas interações com os ambientes em que devem funcionar} (tradução nossa)\footnote{\textit{Holland set out a broad and ambitious agenda for understanding the underlying principles of adaptive systems—systems that are capable of self-modification in response to their interactions with the environments in which they must function.}}. Para \Citet[p. 1]{goldberg_genetic_1989}, Holland tinha dois objetivos principais em sua pesquisa: uma explicação bem estruturada e fundamentada dos processos de adaptação de sistemas naturais e a construção de programas computacionais de sistemas artificiais com a finalidade de incorporar importantes mecanismos destes sistemas, sendo o foco da pesquisa a robustez dos algoritmos, ou seja, o equilíbrio entre a eficiência e a eficácia necessária para a sobrevivência de possíveis soluções em muitos ambientes diferentes.

Diferentemente dos estudos apresentados anteriormente de algoritmos aplicados em modelos de previsão ou otimização, Holland se debruçou sobre modelos evolutivos para entendimento de sistemas adaptativos robustos naturais e projeção de elementos adaptativos em um dado contexto. Para o autor, em sistemas adaptativos naturais, as características relativas à competição e inovação entre os agentes ao longo destes processos naturais eram fundamentais para que os indivíduos se adaptassem ao ambiente e às mudanças imprevistas que este aplicava sobre os indivíduos \Citep{back_handbook_1997}.

O grande deferencial da linha desenvolvida por Holland, foi a incorporação de diversos conceitos da genética (fenótipo, genótipo, reprodução, cruzamento, mutação, entre outros) que se demonstraram altamente eficientes e performáticos na resolução de problemas complexos utilizando poucos dados de entrada, assim como os processos de busca para encontrar soluções ótimas apresentavam inovações em relação à resolução de problemas e aprendizados dos elementos no ambiente ao longo dos processos evolutivos. Dessa forma, como veremos a seguir, a partir de suas primeiras publicações, a Teoria de Sistemas Adaptativos foi se tornando o objeto de estudo de cada vez mais pesquisadores, conquistando um importante espaço no campo de pesquisa da Inteligência Artificial e absorvendo novas ideias das diversas aplicações realizadas, em um grande número de áreas, nas décadas seguintes.

\subsection{A Evolução e as Contribuições Gerais para a Área}
\label{subsec:EvolucaoCampoPesquisaAlgoritmosGeneticos}

\citet{bagley_1967} publica a primeira aplicação, externa ao grupo de pesquisa liderado por Holland, utilizando os conceitos da Teoria de Sistemas Adaptativos. É em seu trabalho que aparece pela primeira vez o termo \enquote{algoritmo genético} \cite[pg.133]{bagley_1967}. Em sua tese, Bagley elabora um programa de testes controlável para aplicação de tarefas a um jogo de \textit{hexapawn}\footnote{Hexapeão, em tradução livre, é um jogo para dois jogadores jogado em um tabuleiro 3 x 3, onde cada jogador começa com 3 peões e tem o objetivo de chegar até a outra extremidade ou impedir o avanço de seu oponente.}. Com um AG que busca por um conjunto de parâmetros através de funções de avaliação do jogo realizado e os compara com outros algoritmos de correlação, o programa ajusta os novos procedimentos conforme os resultados de cada jogo. Segundo \Citet[pg.93]{goldberg_genetic_1989}, Bagley introduz dois conceitos importantes à Teoria: um mecanismo de ajuste da adaptação que reduz as chances de uma solução ser escolhida muito cedo, havendo uma \enquote{super solução} que domina as demais, e que aumenta as chances de seleção de soluções com maior valor de aptidão nas gerações seguintes, aumentando a competitividade; a noção de um AG que se autorregula, sugerindo a codificação das probabilidades de cruzamento e mutação dentro do cromossomo (solução).

No mesmo período, com ênfase nos aspectos biológicos, \Citet{rosenberg_1967}, utilizando um AG, simula uma população de organismos monocelulares em busca dos organismos com as propriedades bioquímicas mais ajustadas a uma estrutura genética arbitrária. Em sua tese, com o cálculo de funções não lineares, Rosenberg faz a primeira aplicação de um AG multiobjetivo que busca o valor máximo de adaptação de uma estrutura específica através da minimização do impacto de organismos com baixo valor de adaptação. 

Absorvendo os novos métodos implementados por Bagley e Rosenberg, \Citet{cavicchio_adaptive_1970} implementa AGs em problemas de seleção de subrotina e problemas de reconhecimento de padrões, inovando com a inserção de um método que ele chamou de esquema de pré seleção, onde uma prole com um bom valor de aptidão substitui seu pai com o objetivo de manter uma população mais diversificada. Com isso, Cavicchio apresenta um dos primeiros estudos sobre formas elitistas de seleção e adaptação de taxas de cruzamento e mutação. No mesmo ano, \Citet{weinberg1969computer}, assim como Rosenberg, aplica AGs para a busca dos cromossomos que melhor se adaptam à uma estrutura genética. Contudo, diferentemente dos trabalhos citados anteriormente, Weinberg sugere a aplicação de um AG para a ajuste dos parâmetros de um AG de nível inferior, chamando o AG de nível mais alto de um programa genético não adaptativo e o AG de nível inferior, onde os parâmetros são ajustados, de programa genético adaptativo. Em outras palavras, o AG de nível superior determina a direção em que o AG de nível inferior evoluirá. Em 1967, Holland começa a elaborar  as primeiras ideias de esquemas de sistemas adaptativos e, em 1969, demonstra aplicações de alocação ótima utilizando o modelo de k-bandidos armados \citeapud{holland_1967}{back_handbook_1997}.

É apenas em 1971 que AGs são aplicados a problemas reais. \Citet{hollstien1971artificial} implementa AGs há um conjunto de 14 problemas de otimização matemática em busca de qual ou quais soluções melhor otimizam o controle de retorno digital de uma determinada planta de engenharia. Uma de suas principais contribuições, foi a observação do impacto negativo que uma população pequena (no caso de sua tese, uma população de 16 indivíduos) tem na robustez do algoritmo e, com isso, recomendando a utilização de populações maiores para futuros testes de otimização. \Citet{frantz_1972} leva em consideração a recomendação de Hollstien. Em seu trabalho, Frantz aplica AGs em uma população de tamanho $n = 100$ vetores de comprimento $l = 25$, com o objetivo de estudar os impactos que a ordem dos genes em um cromossomo, assim como a mudança de posição dos blocos de construção internos do cromossomo, tinha na otimização de AG. As funções configuradas por Frantz para avaliar tais impactos foram não foram robustas o bastante na captação dos impactos, não demonstrando, assim, maiores variações de performance de um ordenamento em relação à outro, considerando o experimento inconclusivo. Contudo, como apontado por \Citet[pg.102]{goldberg_genetic_1989}, Frantz faz duas importantes contribuições através da introdução do operador de complemento parcial e do operador de cruzamento de múltiplos pontos.

Em 1975, Holland reuni as ideias desenvolvidas em sua pesquisa até aquele momento e publica seu principal trabalho, o livro \enquote{\textit{Adaptation in Natural and Artificial Systems}} \Citep{holland_adaptation_1975}. No mesmo ano, \Citet{de_jong_1975}\footnote{Kenneth Allan De Jong foi um dos alunos mais célebres de Holland. Sob sua orientação, recebe seu título de doutor em Ciência da Computação pela Universidade de Michigan em 1975. Com suas pesquisas, De Jong contribuiu para áreas dos AGs, EC, \textit{machine learning} e sistemas adaptativos complexos. Atualmente, é professor emérito em Ciência da Computação na Universidade de Goerge Mason, Virgínia, e um dos principais pesquisadores em CE.} publica sua tese intitulada \enquote{\textit{Analysis of the behavior of a class of genetic adaptive systems}}, uma das publicações mais importantes no campo de estudos dos AGs. Segundo \Citet[pg.107]{goldberg_genetic_1989}, \enquote{O estudo de De Jong permanece um marco no desenvolvimento de algoritmos genéticos devido à combinação da Teoria de Esquema de Holland e seus próprios experimentos computacionais cuidadosos}\footnote{\textit{De Jong's study still stands as a milestone in the development of genetic algorithms because of its combination of Holland's theory of schemata and his own careful compuational experiments.}} (tradução nossa).

De Jong via os AGs como uma ferramenta poderosa e bastante flexível na resolução de um grande número de problemas complexos. Em sua tese, contudo, foca na aplicação de AGs para a otimização de funções, onde descreve minuciosamente os processos realizados pelos AGs na resolução de problemas de otimização, além de refinar e simplificar a configuração de outros elementos importantes como o ambiente e os critérios de desempenho. 

Em um ambiente de testes, De Jong implementou AGs em 5 problemas de minimização de função, avaliando a efetividade de cada AG através de duas métricas: um medidor de convergência e um medidor de convergência contínuo. A primeira foi chamada de medida de performance \textit{off-line} (convergência) enquanto a segunda de medida de performance \textit{on-line} (contínua). O uso de cada métrica dependerá do contexto de aplicação, onde, em uma aplicação \textit{off-line}, era realizada a simulação de avaliação de funções, onde a função com o melhor resultado (média dos melhores valores de performance em cada momento do tempo) seria a escolhida após alcançar um critério de parada predeterminado. Em relação a uma aplicação \textit{on-line}, diferentemente da anterior, a avaliação das funções não é realizada através de simulações, mas sobre dados reais, obtendo, como resultado (média de todas as funções avaliadas), uma recompensa conforme o desempenho da função avaliada pela métrica.

Após definido o ambiente de testes e as métricas de desempenho, De Jong implementou uma primeira versão de um AG que chamou de $R1$ (\textit{reproductive plan 1}), similar ao AG simples apresentado na \autoref{sec:componentes_de_um_algoritmo_genetico}, onde, seguindo um processo aleatório, 3 operadores principais são aplicados sobre uma população de cadeias codificadas de caracteres, sendo eles: i) Operador de reprodução ou seleção; ii) Operador de cruzamento; iii) Operador de mutação. Nesta primeira versão, eram inseridos quatro parâmetros de entrada como o tamanho da população ($n$), a probabilidade de cruzamento ($p_c$), a probabilidade de mutação ($p_m$) e a lacuna de geração ($G$)\footnote{\textit{Generation gap}, ou lacuna de geração em tradução livre, não será um operador que iremos nos aprofundar nestes trabalho. Contudo, em termos gerais, é um método que permite que uma população não sobreponha a outra, convergindo para um resultado muito rápido.}. Os resultados deste primeiro experimento demonstraram algumas características importantes do AG aplicado. Populações maiores tendem a apresentar uma performance melhor em ambientes simulados, em relação à dados reais, devido à alta diversidade entre os indivíduos. No entanto, populações pequenas têm capacidade de adaptação mais rapidamente, apresentando um bom desempenho nas gerações iniciais. O operador de mutação é um importante elemento que diminui a perda de alelos ao longo das gerações, mantendo uma diversidade populacional suficiente para melhoria contínua das populações. Em relação ao operador de reprodução, o autor sugeriu a aplicação de uma probabilidade $p_c = 0,6$ como um valor que equilibrasse a performance tanto no contexto de uma aplicação \textit{off-line} quanto \textit{on-line}. Em outras palavras, para cada 10 indivíduos em uma população, 6 seriam selecionados para cruzamento.

No plano $R2$ (um modelo elitista), De Jong identificou que em superfícies unimodais, o modelo apresentou um crescimento significativo na performance em aplicações \textit{on-line} e \textit{off-line}. Contudo, cruzando estes resultados com o experimento do modelo $R5$ (um modelo de fator de aglomeração), foi identificado que o elitismo nos AGs faz com que o modelo melhore sua performance em relação à busca local em detrimento à busca por ótimos globais. No modelo $R3$ (um modelo de valor esperado), De Jong faz uma outra importante contribuição. Com o objetivo de reduzir os erros estocásticos da seleção aleatória, o autor inseriu no modelo o cálculo do número esperado de proles de cada geração, indicando o quão distante o número de indivíduos simulados ficou do resultado esperado.

Com isso, a segunda metade da década de 1970 foi um marco no campo de pesquisa dos AGs. O interesse pela área foi crescendo progressivamente nos anos seguintes. Em 1976, pesquisadores da Universidade de Michigan, da Universidade de Pittsburgh, entre outras, organizaram a primeira conferência de sistemas adaptativos. Em 1979, Holland, De Jong e Sampson escalam o tamanho da conferência através de um financiamento para realizarem uma conferência interdisciplinar em sistemas adaptativos, que acabou sendo realizado em 1981 na Universidade de Michigan. Em 1985, na Universidade de Pittsburgh, ocorre a primeira Conferência Internacional sobre Algoritmos Genéticos (ICGA) que, devido ao sucesso, passou a ser semestral nos próximos anos. Em 1989, surge a Sociedade Internacional de Algoritmos Genéticos (ISGA), organização responsável pelo financiamento de conferências e atividades das áreas de pesquisas relacionadas aos AGs, tendo como uma de suas primeiras conquistas a criação de uma das principais conferências da comunidade, sobre os Fundamentos dos Algoritmos Genéticos (FOGA) \cite[pg.A2.3:5]{back_handbook_1997}.
